{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, url_for, send_file, jsonify\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils.extract import *\n",
    "from utils.voc_grading_and_detail import *\n",
    "from utils.create_pdf import *\n",
    "from utils.grammar_pattern import *\n",
    "from utils.autoFindPattern import *\n",
    "from readability import Document\n",
    "\n",
    "from utils.create_pdf.create_flashcard import *\n",
    "from utils.create_pdf.create_article import *\n",
    "from utils.create_pdf.create_wordlist import *\n",
    "from utils.create_pdf.create_grammar import *\n",
    "from utils.create_pdf.stylesheet import *\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read statistics file\n",
    "file = open('utils/data/autoFindPattern/statistics(V).txt', 'r')\n",
    "dictV =  defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0)))) \n",
    "for line in file:\n",
    "    word, subDict = line.split('\\t')\n",
    "    dictV[word] = eval(subDict)\n",
    "file.close()\n",
    "\n",
    "file = open('utils/data/autoFindPattern/statistics(N).txt', 'r')\n",
    "dictN =  defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0)))) \n",
    "for line in file:\n",
    "    word, subDict = line.split('\\t')\n",
    "    dictN[word] = eval(subDict)\n",
    "file.close()\n",
    "\n",
    "file = open('utils/data/autoFindPattern/statistics(Adj).txt', 'r')\n",
    "dictAdj =  defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0)))) \n",
    "for line in file:\n",
    "    word, subDict = line.split('\\t')\n",
    "    dictAdj[word] = eval(subDict)\n",
    "file.close()\n",
    "\n",
    "\n",
    "# read statistic key\n",
    "file = open('utils/data/autoFindPattern/keys(V).txt', 'r')\n",
    "verb_set = eval(file.readline())\n",
    "file.close()\n",
    "\n",
    "file = open('utils/data/autoFindPattern/keys(N).txt', 'r')\n",
    "noun_set = eval(file.readline())\n",
    "file.close()\n",
    "\n",
    "file = open('utils/data/autoFindPattern/keys(Adj).txt', 'r')\n",
    "adj_set = eval(file.readline())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [17/Jun/2018 19:24:10] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jun/2018 19:24:49] \"POST /handle_data HTTP/1.1\" 400 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__ )\n",
    "\n",
    "stylesheet = stylesheet() # pdf stylesheet\n",
    "# egp = load_egp() # grammar pattern\n",
    "\n",
    "if not os.path.exists('download'):\n",
    "    os.makedirs('download')\n",
    "\n",
    "@app.route('/', methods=['POST', 'GET'])\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "    #return render_template('format.html', title=title, publish_date=publish_date, content=new, user_level=user_level, grade=grade)\n",
    "\n",
    "@app.route('/handle_data', methods=['POST', 'GET'])\n",
    "def handle_data():\n",
    "    url = request.form['url']\n",
    "    #user_level = request.form['user_level']\n",
    "    response = requests.get(url)\n",
    "\n",
    "    doc = Document(remove_a(response.text))\n",
    "    title = doc.short_title()\n",
    "    publish_date = getPublishDate(url)\n",
    "    content = clean_content(doc.summary())\n",
    "    #grade, wordlist = voc_grading_and_detail(content, user_level)\n",
    "    #patterns = findGramPat(content)\n",
    "    # create pdf\n",
    "    #new = create_article(title, content, stylesheet, grade, 'download/'+title+'_article.pdf')\n",
    "    #print(content)\n",
    "    new = create_article(title, content, stylesheet,  'download/'+title+'_article.pdf', verb_set, noun_set, adj_set)\n",
    "    #create_wordlist(wordlist, patterns, 'download/'+title+'_wordlist.pdf')\n",
    "    # create_grammar(title, original, stylesheet, egp, 'download/'+title+'_grammar.pdf')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return render_template('format.html', title=title, publish_date=publish_date, content=new) #, user_level=user_level , grade=grade\n",
    "\n",
    "@app.route('/download/<filename>', methods=['GET'])\n",
    "def return_reformatted(filename):\n",
    "    try:\n",
    "        return send_file('download/'+filename)# , as_attachment=True\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "@app.route('/ajax', methods = ['POST'])\n",
    "def ajax_request():\n",
    "    word = request.form['word'].lower() if request.form['pos'] != 'x' else request.form['word'].split()[0].lower()  \n",
    "    pos = [request.form['pos']] if request.form['pos'] != 'x' else [p.upper() for p in request.form['word'].split()[1:]]\n",
    "    \n",
    "    targetList = []\n",
    "    targetDict = dict()\n",
    "    if 'V' in pos: targetList.append(dictV)\n",
    "    if 'N' in pos: targetList.append(dictN)\n",
    "    if 'ADJ' in pos: targetList.append(dictAdj)\n",
    "    if not targetList: targetList = [dictV, dictN, dictAdj]\n",
    "    \n",
    "    result = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: ''))) # result[pos][pat][obj] = highlight\n",
    "    patPair = defaultdict(lambda: []) # patPair[pos] = [pat...]\n",
    "    objs = defaultdict(lambda: defaultdict(lambda: [])) # objs[pos][pat] = [obj...]\n",
    "        \n",
    "    for targetDict in targetList:\n",
    "        if targetDict == dictV: mark = 'V'\n",
    "        elif targetDict == dictN: mark = 'N'\n",
    "        else: mark = 'ADJ'\n",
    "            \n",
    "        if word in targetDict.keys():\n",
    "            patPair[mark] = sorted(targetDict[word].keys(), key=lambda x: -(int(x.rsplit('%', 1)[1])))[:5]\n",
    "            subpatPair = patPair[mark]\n",
    "            \n",
    "            sub_objs = defaultdict(lambda: []) # objs[pat] = [obj...]\n",
    "\n",
    "            for pat in subpatPair:\n",
    "                objPair = sorted(targetDict[word][pat].keys(), key=lambda x: -(int(x.rsplit('%', 1)[1])))[:3]\n",
    "                # move '-' to list end\n",
    "                emptys = [pair for pair in objPair if pair.startswith('-')]\n",
    "                for empty in emptys:\n",
    "                    objPair.remove(empty)\n",
    "                    objPair += [empty]\n",
    "\n",
    "                sub_objs[pat] += objPair\n",
    "                for obj in objPair:\n",
    "                    highlight = sorted(targetDict[word][pat][obj].items(), key=lambda x: -x[1])[0]\n",
    "                    result[mark][pat][obj] = highlight[0]\n",
    "                    \n",
    "            objs[mark] = sub_objs\n",
    "                      \n",
    "    return jsonify(table=result, patterns=patPair, objs=objs)\n",
    "\n",
    "#static url cache buster\n",
    "@app.context_processor\n",
    "def override_url_for():\n",
    "    return dict(url_for=dated_url_for)\n",
    "\n",
    "def dated_url_for(endpoint, **values):\n",
    "    if endpoint == 'static':\n",
    "        filename = values.get('filename', None)\n",
    "        if filename:\n",
    "            file_path = os.path.join(app.root_path,\n",
    "                                     endpoint, filename)\n",
    "            values['q'] = int(os.stat(file_path).st_mtime)\n",
    "    return url_for(endpoint, **values)   \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)\n",
    "    #app.run(host='0.0.0.0', port=int(\"9487\"), debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
